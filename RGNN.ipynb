{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Nov 30 19:48:58 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.66       Driver Version: 450.66       CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro RTX 8000     On   | 00000000:19:00.0 Off |                  Off |\n",
      "| 34%   38C    P8    32W / 260W |   1202MiB / 48601MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Quadro RTX 8000     On   | 00000000:1A:00.0 Off |                  Off |\n",
      "| 46%   69C    P2   128W / 260W |  45792MiB / 48601MiB |     45%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Quadro RTX 8000     On   | 00000000:67:00.0 Off |                  Off |\n",
      "| 34%   47C    P8    35W / 260W |  46614MiB / 48601MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Quadro RTX 8000     On   | 00000000:68:00.0 Off |                  Off |\n",
      "| 33%   47C    P8    31W / 260W |   7026MiB / 48598MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1251      C   ...cd-add2-00cd65417a62.json      197MiB |\n",
      "|    0   N/A  N/A      1618      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    0   N/A  N/A     13317      C   ...86-8017-081b19e16e24.json      197MiB |\n",
      "|    0   N/A  N/A     31445      C   ...9885/anaconda3/bin/python      797MiB |\n",
      "|    1   N/A  N/A      1251      C   ...cd-add2-00cd65417a62.json      197MiB |\n",
      "|    1   N/A  N/A      1618      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    1   N/A  N/A     13317      C   ...86-8017-081b19e16e24.json      197MiB |\n",
      "|    1   N/A  N/A     33145      C   python                          45387MiB |\n",
      "|    2   N/A  N/A      1251      C   ...cd-add2-00cd65417a62.json      197MiB |\n",
      "|    2   N/A  N/A      1618      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    2   N/A  N/A      2842      C   ...da3/envs/myenv/bin/python    46209MiB |\n",
      "|    2   N/A  N/A     13317      C   ...86-8017-081b19e16e24.json      197MiB |\n",
      "|    3   N/A  N/A      1251      C   ...cd-add2-00cd65417a62.json      197MiB |\n",
      "|    3   N/A  N/A      1618      G   /usr/lib/xorg/Xorg                 63MiB |\n",
      "|    3   N/A  N/A      1831      G   /usr/bin/gnome-shell                9MiB |\n",
      "|    3   N/A  N/A     13317      C   ...86-8017-081b19e16e24.json      197MiB |\n",
      "|    3   N/A  N/A     13869      C   ...da3/envs/myenv/bin/python     6553MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib import cm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import datetime\n",
    "import time\n",
    "%matplotlib notebook\n",
    "from IPython.core.debugger import set_trace\n",
    "from torch_geometric.data import Data, Dataset, InMemoryDataset, DataLoader,DataListLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Sequential, Linear, ReLU, GRU, BatchNorm1d, LayerNorm\n",
    "from torch_geometric.nn import GCNConv, GENConv, DeepGCNLayer, DataParallel\n",
    "import pyvista as pv\n",
    "from threading import Thread\n",
    "import vtk\n",
    "from IPython.display import HTML, display\n",
    "from pyvirtualdisplay import Display\n",
    "from pathlib import Path\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "pv.set_plot_theme(\"document\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_simulation_input(simulation_id, simulation_result_path = '/home/mmv664/Documents/Graph_modeling/AutoGAMMA/2_simulation_results'):\n",
    "    edge_index_list = []\n",
    "    pos_list = []\n",
    "    elements = []\n",
    "    birth_list_element = []\n",
    "    birth_list_node = []\n",
    "    with open('{}/{}/gamma/{}.k'.format(simulation_result_path, simulation_id, simulation_id)) as f:\n",
    "        while True:\n",
    "            line = next(f)\n",
    "            if not line.split():\n",
    "                continue\n",
    "            if line.split()[0] == '*NODE':\n",
    "                first = True\n",
    "                while True:\n",
    "                    line = next(f)\n",
    "                    if line[0] == '*':\n",
    "                        break\n",
    "                    if line[0] == '$':\n",
    "                        continue\n",
    "                    text = line.split()\n",
    "                    if first:\n",
    "                        node_base = int(text[0])\n",
    "                        first = False\n",
    "                    pos_list.append([float(text[1]),float(text[2]),float(text[3])])\n",
    "            if line.split()[0] == '*END':\n",
    "                break  \n",
    "    birth_list_node = [-1 for _ in range(len(pos_list))]\n",
    "    with open('{}/{}/gamma/{}.k'.format(simulation_result_path, simulation_id, simulation_id)) as f:\n",
    "        while True:\n",
    "            line = next(f)\n",
    "            if not line.split():\n",
    "                continue\n",
    "            if line.split()[0] == '*ELEMENT_SOLID':\n",
    "                first = True\n",
    "                while True:\n",
    "                    line = next(f)\n",
    "                    if line[0] == '*':\n",
    "                        break\n",
    "                    if line[0] == '$':\n",
    "                        continue\n",
    "                    text = line.split()\n",
    "                    if first:\n",
    "                        element_base = int(text[0])\n",
    "                        first = False\n",
    "                    elements.append([int(text[2])-node_base, int(text[3])-node_base, int(text[4])-node_base, int(text[5])-node_base,\n",
    "                                     int(text[6])-node_base, int(text[7])-node_base, int(text[8])-node_base, int(text[9])-node_base])\n",
    "                    for source_ind in range(2, 10):\n",
    "                        for taget_ind in range(2, 10):\n",
    "                            if source_ind == taget_ind:\n",
    "                                continue\n",
    "                            edge_index_list.append([int(text[source_ind])-node_base, int(text[taget_ind])-node_base])\n",
    "            if line.split()[0] == '*END':\n",
    "                break\n",
    "    birth_list_element = [-1.0]*len(elements)\n",
    "    with open('{}/{}/gamma/{}.k'.format(simulation_result_path, simulation_id, simulation_id)) as f:\n",
    "        while True:\n",
    "            line = next(f)\n",
    "            if not line.split():\n",
    "                continue\n",
    "            if line.split()[0] == '*DEFINE_CURVE':\n",
    "                while True:\n",
    "                    line = next(f)\n",
    "                    if line[0] == '*':\n",
    "                        break\n",
    "                    if line[0] == '$':\n",
    "                        continue\n",
    "                    text = line.split()\n",
    "                    birth_list_element[int(float(text[1]))-element_base] = float(text[0])\n",
    "            if line.split()[0] == '*END':\n",
    "                break     \n",
    "    \n",
    "    for element, birth_element in zip(elements, birth_list_element):\n",
    "        if birth_element < 0:\n",
    "            continue\n",
    "        for node in element:\n",
    "            if (birth_list_node[node] > birth_element or \n",
    "                                        birth_list_node[node] < 0):\n",
    "                                    birth_list_node[node] = birth_element\n",
    "\n",
    "    edge_index = torch.tensor(edge_index_list ,dtype=torch.long)\n",
    "    elements = torch.tensor(elements ,dtype=torch.long)\n",
    "    pos = torch.tensor(pos_list ,dtype=torch.float)\n",
    "    birth_element = torch.tensor(birth_list_element, dtype=torch.float)\n",
    "    birth_node = torch.tensor(birth_list_node, dtype=torch.float)\n",
    "    return edge_index, elements, pos, birth_element, birth_node\n",
    "\n",
    "def load_toolpath(simulation_id, simulation_result_path = '/home/mmv664/Documents/Graph_modeling/AutoGAMMA/2_simulation_results', dt = 0.1):\n",
    "    file = '{}/{}/gamma/toolpath.crs'.format(simulation_result_path, simulation_id)\n",
    "    toolpath_raw=pd.read_table(file, delimiter=r\"\\s+\",header=None, names=['time','x','y','z','state'])\n",
    "    toolpath=[]\n",
    "    state=[]\n",
    "    time=0.0\n",
    "    ind=0\n",
    "    endTime = float(toolpath_raw.tail(1)['time'])\n",
    "    while(time<=endTime):\n",
    "        while(time>=toolpath_raw['time'][ind+1]):\n",
    "            ind=ind+1\n",
    "        X=toolpath_raw['x'][ind]+(toolpath_raw['x'][ind+1]-toolpath_raw['x'][ind])*(\n",
    "            time-toolpath_raw['time'][ind])/(toolpath_raw['time'][ind+1]-toolpath_raw['time'][ind])\n",
    "        Y=toolpath_raw['y'][ind]+(toolpath_raw['y'][ind+1]-toolpath_raw['y'][ind])*(\n",
    "            time-toolpath_raw['time'][ind])/(toolpath_raw['time'][ind+1]-toolpath_raw['time'][ind])\n",
    "        Z=toolpath_raw['z'][ind]+(toolpath_raw['z'][ind+1]-toolpath_raw['z'][ind])*(\n",
    "            time-toolpath_raw['time'][ind])/(toolpath_raw['time'][ind+1]-toolpath_raw['time'][ind])\n",
    "        toolpath.append([X,Y,Z])\n",
    "        state.append(toolpath_raw['state'][ind+1])\n",
    "        time = time +dt\n",
    "    return toolpath, state, endTime\n",
    "\n",
    "def load_simulation_output(simulation_id, simulation_result_path = '/home/mmv664/Documents/Graph_modeling/AutoGAMMA/2_simulation_results'):\n",
    "    temperature = pd.read_csv('{}/{}/gamma/{}.csv'.format(simulation_result_path, simulation_id, simulation_id))\n",
    "    temperature.drop(temperature.columns[len(temperature.columns)-1], axis=1, inplace=True)\n",
    "    return torch.tensor(temperature.values, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdditiveThermalDataset(Dataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None, normalize=True):\n",
    "        self.seq_len = 30 # length of each sample\n",
    "        self.sample_per_simulation = 100 # number of samples in each simulation\n",
    "        # self.simulation_ids = ['17', '18', '19'] # for testing\n",
    "        self.simulation_ids = [x.stem for x in Path('/home/mmv664/Documents/Graph_modeling/AutoGAMMA/2_simulation_results').iterdir() if x.is_dir()]\n",
    "        self.normalize = normalize\n",
    "        if normalize:\n",
    "            self.stats = torch.load(\"/home/mmv664/Documents/Graph_modeling/Graph_AM_Modeling/processed/stats\")\n",
    "        super(AdditiveThermalDataset, self).__init__(root, transform, pre_transform)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return []\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['am_graph.simul0.data0']\n",
    "\n",
    "    def download(self):\n",
    "        pass\n",
    "    \n",
    "    def process(self):\n",
    "        \n",
    "        i = 0 # simulation_idx\n",
    "        for simulation_id in self.simulation_ids:\n",
    "            print(\"processing simulation {}!\".format(simulation_id))\n",
    "            j = 0 # time_idx\n",
    "        \n",
    "            # load simulation settings\n",
    "            edge_index, elements, pos, birth_element, birth = load_simulation_input(simulation_id)\n",
    "            toolpath, state, endTime = load_toolpath(simulation_id)\n",
    "            \n",
    "            # temperature output\n",
    "            temperature = load_simulation_output(simulation_id)\n",
    "            temperature = torch.clamp(temperature, 300.0, 2000.0)\n",
    "\n",
    "            # edge feature (length of each edge)\n",
    "            edge_pos = pos[edge_index.long()]\n",
    "            edge_dis = ((edge_pos[:, 0, :] - edge_pos[:, 1, :])**2).sum(dim = 1)\n",
    "            \n",
    "            # boundary feature (distance to fixed boundary condition at z = -20)\n",
    "            boundary = pos[:, 2] + 20.0\n",
    "\n",
    "            assert (temperature.shape[1] == pos.shape[0])\n",
    "\n",
    "            seed = np.random.permutation(temperature.shape[0]-self.seq_len)[0:self.sample_per_simulation] # the starting time of each sample \n",
    "            torch.save(seed, osp.join(self.processed_dir, 'simul{}.seed'.format(i)))\n",
    "            j = 0\n",
    "            for start_time in seed:\n",
    "                x_data = torch.Tensor([])\n",
    "                y_data = torch.Tensor([])\n",
    "                birth_data = torch.Tensor([])\n",
    "                for time_step in range(start_time, start_time + self.seq_len):\n",
    "                    toolpath_current_step = toolpath[time_step]\n",
    "                    state_current_step = state[time_step]   \n",
    "                    r2 = (pos[:, 0] - toolpath_current_step[0])**2 + (pos[:, 1] - toolpath_current_step[1])**2 + (pos[:, 2] - toolpath_current_step[2])**2 + 0.1\n",
    "                    if state_current_step == 1:\n",
    "                        laser_feature = 1/r2\n",
    "                    else:\n",
    "                        laser_feature = r2 * 0.0                   \n",
    "\n",
    "                    temp_time_step = temperature[time_step, :]\n",
    "                    # temp_time_step_next = temperature[time_step + 1, :]\n",
    "\n",
    "                    birth_time_step = (birth < time_step * 0.1).float()\n",
    "                    # birth_time_step_next = (birth < (time_step + 1) * 0.1).float()\n",
    "\n",
    "                    birth_time_element = (birth_element < time_step * 0.1).float()\n",
    "\n",
    "                    x = torch.cat([\n",
    "                    #              temp_time_step.unsqueeze(1),\n",
    "                                   birth_time_step.unsqueeze(1),\n",
    "                                   boundary.unsqueeze(1),\n",
    "                                   laser_feature.unsqueeze(1)], dim = 1)\n",
    "                    y = torch.cat([temp_time_step.unsqueeze(1),\n",
    "                    #              temp_time_step_next.unsqueeze(1),\n",
    "                    #              birth_time_step_next.unsqueeze(1)\n",
    "                                  ], dim = 1)\n",
    "\n",
    "                    x_data = torch.cat((x_data, x.unsqueeze(0)),0)\n",
    "                    y_data = torch.cat((y_data, y.unsqueeze(0)),0)\n",
    "                    birth_data = torch.cat((birth_data, birth_time_element.unsqueeze(0)),0)\n",
    "\n",
    "                data = Data(x=x_data, y=y_data, birth_element=birth_data)\n",
    "                torch.save(data, osp.join(self.processed_dir, 'am_graph.simul{}.data{}'.format(i,j)))\n",
    "\n",
    "                j = j + 1\n",
    "                if j%40 == 0:\n",
    "                    print(\"{:.2f} %\".format(j/2))\n",
    "\n",
    "            const_data = Data(pos = pos, edge_index=edge_index.t().contiguous(), edge_attr = edge_dis, elements=elements)\n",
    "            torch.save(const_data, osp.join(self.processed_dir, 'am_graph.simul{}.const'.format(i)))\n",
    "            i += 1\n",
    "            \n",
    "    def len(self):\n",
    "        return self.sample_per_simulation * len(self.simulation_ids)\n",
    "\n",
    "    def get(self, idx):\n",
    "        i = idx//self.sample_per_simulation\n",
    "        j = idx%self.sample_per_simulation\n",
    "        constant_data = torch.load(osp.join(self.processed_dir, 'am_graph.simul{}.const'.format(i)))\n",
    "        data = torch.load(osp.join(self.processed_dir, 'am_graph.simul{}.data{}'.format(i,j)))\n",
    "        data_x = data['x']\n",
    "        data_x[:,:,2] = self.smooth(data['x'][:,:,2].clamp(0, 1.0), base_temp = 0.35)\n",
    "        data_e = constant_data['edge_attr']\n",
    "        \n",
    "        data_y = self.smooth(data['y'], base_temp = 5000)\n",
    "       \n",
    "        if self.normalize:\n",
    "            # normalize boundary feature to the range of 0-1\n",
    "            data_x[:,:,1] = (data_x[:,:,1] - self.stats[1,2]) / (self.stats[1,3] - self.stats[1,2])\n",
    "            # normalize laser feature to mean of zeros and std of 1\n",
    "            #data_x[:,:,2] = (data_x[:,:,2] - self.stats[2,2]) / (self.stats[2,3] - self.stats[2,2])\n",
    "            # nomalize edge feature to mean of zero and std of 1\n",
    "            data_e = 1.0/data_e**0.5\n",
    "            # normalize temperature to the range of 0-1\n",
    "            data_y = (data_y - 300) / 6200 # max_temp ~6500\n",
    "            #data_y = (data_y - self.stats[3,2]) / (self.stats[3,3] - self.stats[3,2])\n",
    "            \n",
    "        return Data(\n",
    "                    x=data_x.transpose(0,1)[:,0:self.seq_len,:], \n",
    "                    y=data_y.transpose(0,1)[:,0:self.seq_len,:], \n",
    "                    pos=constant_data['pos'], \n",
    "                    edge_index=constant_data['edge_index'],\n",
    "                    edge_attr=data_e.unsqueeze(1),\n",
    "                    birth_element=data['birth_element'].transpose(0,1)[:,0:self.seq_len],\n",
    "                    elements=constant_data['elements']\n",
    "                   )\n",
    "    def smooth(self, data, base_temp = 5000):\n",
    "        added = (data - base_temp).clamp(min = 0) / 10\n",
    "        final = data.clamp(max = base_temp) + added\n",
    "        return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = AdditiveThermalDataset('/home/mmv664/Documents/Graph_modeling/Graph_AM_Modeling', normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 500)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_simulations = 5\n",
    "#train_samples = 10000\n",
    "test_start_index = (len(dataset.simulation_ids) - test_simulations)* dataset.sample_per_simulation\n",
    "train_dataset = dataset[:test_start_index]\n",
    "train_dataset = train_dataset.shuffle()\n",
    "#train_dataset = train_dataset[:train_samples]\n",
    "test_dataset = dataset[test_start_index:]\n",
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "#train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True)\n",
    "#test_loader = DataLoader(test_dataset, batch_size = batch_size)\n",
    "train_loader = DataListLoader(train_dataset, batch_size = batch_size, shuffle=True)\n",
    "test_loader = DataListLoader(test_dataset, batch_size = batch_size)\n",
    "visualization_loader = DataListLoader(train_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # only run for the first time when building the stats, other times stats can be just loaded from AdditiveThermalDataset\n",
    "\n",
    "# sums, squared_sums, num_sample, min_, max_ = torch.zeros(4), torch.zeros(4), torch.zeros(4), torch.ones(4) * 1e10, torch.ones(4) * -1e10\n",
    "# sums_e, squared_sums_e, num_sample_e, min_e, max_e = torch.zeros(1), torch.zeros(1), torch.zeros(1), torch.ones(1) * 1e10, torch.ones(1) * -1e10\n",
    "\n",
    "# for data in train_dataset:\n",
    "#     data_xy = torch.cat((data.x, data.y), 2)\n",
    "#     data_e = data.edge_attr\n",
    "#     sums += torch.sum(data_xy, dim=[0,1])\n",
    "#     sums_e += torch.sum(data_e, dim=[0])\n",
    "#     squared_sums += torch.sum(data_xy**2, dim=[0, 1])\n",
    "#     squared_sums_e += torch.sum(data_e**2, dim=[0])\n",
    "#     num_sample += data_xy.shape[0] * data_xy.shape[1]\n",
    "#     num_sample_e += data_e.shape[0]\n",
    "#     min_ = torch.min(min_, data_xy.view(-1,data_xy.shape[-1]).min(dim=0).values)\n",
    "#     max_ = torch.max(max_, data_xy.view(-1,data_xy.shape[-1]).max(dim=0).values)\n",
    "#     min_e = torch.min(min_e, data_e.min(dim=0).values)\n",
    "#     max_e = torch.max(max_e, data_e.max(dim=0).values)    \n",
    "\n",
    "# mean = sums/num_sample\n",
    "# std = (squared_sums/num_sample - mean**2)**0.5\n",
    "# mean_e = sums_e/num_sample_e\n",
    "# std_e = (squared_sums_e/num_sample_e - mean_e**2)**0.5\n",
    "\n",
    "# stats_xy = torch.cat((mean.unsqueeze(1),\n",
    "#                   std.unsqueeze(1), \n",
    "#                   min_.unsqueeze(1),\n",
    "#                   max_.unsqueeze(1)),\n",
    "#                   1)\n",
    "# stats_e = torch.cat((mean_e, std_e, min_e, max_e)).unsqueeze(0)\n",
    "# stats = torch.cat((stats_xy, stats_e), 0)\n",
    "# torch.save(stats, \"processed/stats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 8\n",
    "input_features = 3\n",
    "output_features = 1\n",
    "num_layers = 6\n",
    "#dropout = 0.\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.node_encoder = Linear(input_features, dim)\n",
    "        self.edge_encoder = Linear(1, dim)\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        for i in range(1, num_layers + 1):\n",
    "            conv = GENConv(dim, dim, aggr='softmax',\n",
    "                           t=1.0, learn_t=True, num_layers=2, norm='layer')\n",
    "            norm = LayerNorm(dim, elementwise_affine=True)\n",
    "            act = ReLU(inplace=True)\n",
    "            layer = DeepGCNLayer(conv, norm, act, block='res+', dropout=0.1,\n",
    "                                 ckpt_grad=i % 3)\n",
    "            self.layers.append(layer)\n",
    "\n",
    "        self.lin = Linear(dim, output_features)\n",
    "        \n",
    "        self.gru1 = torch.nn.GRU(dim, dim, num_layers=3)\n",
    "        self.gru2 = torch.nn.GRU(dim, 1)\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, data):\n",
    "        X, Y, edge_index, edge_attr = data.x, data.y, data.edge_index, data.edge_attr\n",
    "        edge_attr = self.edge_encoder(edge_attr)\n",
    "        # extract features from time sequence \n",
    "        for i in range(1,X.shape[1]):\n",
    "            x = X[:,i,:]\n",
    "            x = self.node_encoder(x)\n",
    "            \n",
    "            feature = self.layers[0].conv(x, edge_index, edge_attr)\n",
    "            \n",
    "            for layer in self.layers[1:]:\n",
    "                feature = layer(feature, edge_index, edge_attr)\n",
    "                \n",
    "            feature = self.layers[0].act(self.layers[0].norm(feature))\n",
    "            feature = F.dropout(feature, p=0.1, training=self.training)\n",
    "            \n",
    "            if i == 1:\n",
    "                features = feature.unsqueeze(0)\n",
    "            else:\n",
    "                features = torch.cat((features, feature.unsqueeze(0)),0)\n",
    "        \n",
    "        # initial state: node birth info\n",
    "        h_0 = X[:,0,0].reshape(1,-1,1).repeat([3,1,dim]).contiguous()\n",
    "        out,h = self.gru1(features,h_0)\n",
    "        \n",
    "        # initial state: temp\n",
    "        h_0 = Y[:,0,:].unsqueeze(0).contiguous()\n",
    "        out,h = self.gru2(out,h_0)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir='results/{}'.format(datetime.datetime.now().strftime(\"%Y-%m-%d--%H-%M-%S\"))\n",
    "description = \"\"\n",
    "\n",
    "os.makedirs(logdir, exist_ok=True)\n",
    "writer = SummaryWriter(logdir)\n",
    "writer.add_text(\"Final_model\", description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net()\n",
    "model = DataParallel(model)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for data_list in train_loader:\n",
    "        predict = model(data_list)\n",
    "        # mask the node not born \n",
    "#         output = data_list[0].y[:,1:,:].transpose(0,1).to(device)\n",
    "#         birth = data_list[0].x[:,1:,0].transpose(0,1).to(device)\n",
    "#         loss = F.mse_loss(predict[:,:,0]*birth, output[:,:,0]*birth)*birth.shape[0]*birth.shape[1]/birth.sum()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(loader):\n",
    "    model.train()\n",
    "    loss_all = 0\n",
    "    for data_list in loader:\n",
    "        optimizer.zero_grad()\n",
    "        predict = model(data_list)\n",
    "        # mask the node not born \n",
    "        output = data_list[0].y[:,1:,:].transpose(0,1).to(device)\n",
    "        #birth = data_list[0].x[:,1:,0].transpose(0,1).to(device)\n",
    "        #loss = F.mse_loss(predict[:,:,0]*birth, output[:,:,0]*birth)*birth.shape[0]*birth.shape[1]/birth.sum()\n",
    "        loss = F.mse_loss(predict[:,:,0], output[:,:,0])\n",
    "        loss.backward()\n",
    "        loss_all += len(data_list) * loss.item()\n",
    "        optimizer.step()\n",
    "    return loss_all / (len(loader) * loader.batch_size)\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    loss_all = 0\n",
    "    with torch.no_grad():\n",
    "        for data_list in loader:\n",
    "            predict = model(data_list)\n",
    "             # mask the node not born\n",
    "            output = data_list[0].y[:,1:,:].transpose(0,1).to(device)\n",
    "            #birth = data_list[0].x[:,1:,0].transpose(0,1).to(device)\n",
    "            #loss = F.mse_loss(predict[:,:,0]*birth, output[:,:,0]*birth)*birth.shape[0]*birth.shape[1]/birth.sum()\n",
    "            loss = F.mse_loss(predict[:,:,0], output[:,:,0])\n",
    "            loss_all += len(data_list) * loss.item()\n",
    "    return loss_all / (len(loader) * loader.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:38:05] Epoch: 000, Train loss: 2.43E-02, Test loss: 8.95E-04 \n",
      "[03:03:34] Epoch: 001, Train loss: 5.53E-04, Test loss: 2.98E-04 \n",
      "[05:29:12] Epoch: 002, Train loss: 2.17E-04, Test loss: 1.73E-04 \n",
      "[07:54:54] Epoch: 003, Train loss: 1.42E-04, Test loss: 1.10E-04 \n",
      "[10:20:50] Epoch: 004, Train loss: 8.10E-05, Test loss: 5.27E-05 \n",
      "[12:46:27] Epoch: 005, Train loss: 5.24E-05, Test loss: 4.22E-05 \n",
      "[15:13:19] Epoch: 006, Train loss: 4.58E-05, Test loss: 4.66E-05 \n",
      "[17:39:55] Epoch: 007, Train loss: 4.23E-05, Test loss: 3.89E-05 \n",
      "[20:06:09] Epoch: 008, Train loss: 3.97E-05, Test loss: 3.60E-05 \n",
      "[22:32:17] Epoch: 009, Train loss: 3.80E-05, Test loss: 3.42E-05 \n",
      "[00:58:11] Epoch: 010, Train loss: 3.62E-05, Test loss: 3.35E-05 \n",
      "[03:24:43] Epoch: 011, Train loss: 3.48E-05, Test loss: 3.15E-05 \n",
      "[05:50:23] Epoch: 012, Train loss: 3.35E-05, Test loss: 2.98E-05 \n",
      "[08:16:19] Epoch: 013, Train loss: 3.23E-05, Test loss: 3.18E-05 \n",
      "[10:42:32] Epoch: 014, Train loss: 3.15E-05, Test loss: 2.75E-05 \n",
      "[13:08:20] Epoch: 015, Train loss: 3.04E-05, Test loss: 2.72E-05 \n",
      "[15:34:01] Epoch: 016, Train loss: 3.01E-05, Test loss: 2.78E-05 \n",
      "[18:00:10] Epoch: 017, Train loss: 2.93E-05, Test loss: 3.85E-05 \n",
      "[20:26:18] Epoch: 018, Train loss: 2.89E-05, Test loss: 3.04E-05 \n",
      "[22:53:42] Epoch: 019, Train loss: 2.84E-05, Test loss: 2.57E-05 \n",
      "[01:21:09] Epoch: 020, Train loss: 2.81E-05, Test loss: 2.63E-05 \n",
      "[03:49:46] Epoch: 021, Train loss: 2.76E-05, Test loss: 2.73E-05 \n",
      "[06:19:03] Epoch: 022, Train loss: 2.72E-05, Test loss: 2.52E-05 \n",
      "[08:47:59] Epoch: 023, Train loss: 2.70E-05, Test loss: 2.69E-05 \n",
      "[11:16:19] Epoch: 024, Train loss: 2.67E-05, Test loss: 2.38E-05 \n",
      "[13:44:17] Epoch: 025, Train loss: 2.66E-05, Test loss: 2.56E-05 \n",
      "[16:12:46] Epoch: 026, Train loss: 2.62E-05, Test loss: 2.64E-05 \n",
      "[18:42:24] Epoch: 027, Train loss: 2.58E-05, Test loss: 2.67E-05 \n",
      "[21:10:56] Epoch: 028, Train loss: 2.59E-05, Test loss: 2.57E-05 \n",
      "[23:39:02] Epoch: 029, Train loss: 2.54E-05, Test loss: 2.57E-05 \n",
      "[02:08:01] Epoch: 030, Train loss: 2.53E-05, Test loss: 2.37E-05 \n",
      "[04:37:09] Epoch: 031, Train loss: 2.51E-05, Test loss: 2.92E-05 \n",
      "[07:05:55] Epoch: 032, Train loss: 2.50E-05, Test loss: 2.37E-05 \n",
      "[09:35:11] Epoch: 033, Train loss: 2.49E-05, Test loss: 2.51E-05 \n",
      "[12:04:03] Epoch: 034, Train loss: 2.47E-05, Test loss: 2.41E-05 \n",
      "[14:32:50] Epoch: 035, Train loss: 2.44E-05, Test loss: 3.52E-05 \n",
      "[17:01:43] Epoch: 036, Train loss: 2.43E-05, Test loss: 2.29E-05 \n",
      "[19:33:07] Epoch: 037, Train loss: 2.42E-05, Test loss: 2.30E-05 \n",
      "[22:02:53] Epoch: 038, Train loss: 2.39E-05, Test loss: 2.26E-05 \n",
      "[00:34:17] Epoch: 039, Train loss: 2.38E-05, Test loss: 2.29E-05 \n",
      "[03:04:15] Epoch: 040, Train loss: 2.37E-05, Test loss: 2.33E-05 \n",
      "[05:33:15] Epoch: 041, Train loss: 2.36E-05, Test loss: 2.80E-05 \n",
      "[08:02:14] Epoch: 042, Train loss: 2.34E-05, Test loss: 2.50E-05 \n",
      "[10:28:54] Epoch: 043, Train loss: 2.35E-05, Test loss: 2.38E-05 \n",
      "[12:59:20] Epoch: 044, Train loss: 2.33E-05, Test loss: 2.34E-05 \n",
      "[15:28:47] Epoch: 045, Train loss: 2.30E-05, Test loss: 2.17E-05 \n",
      "[17:57:51] Epoch: 046, Train loss: 2.31E-05, Test loss: 2.35E-05 \n",
      "[20:27:29] Epoch: 047, Train loss: 2.27E-05, Test loss: 2.40E-05 \n",
      "[22:56:21] Epoch: 048, Train loss: 2.27E-05, Test loss: 2.18E-05 \n"
     ]
    }
   ],
   "source": [
    "his = []\n",
    "# trian_loss = test(train_loader)\n",
    "# test_loss = test(test_loader)\n",
    "# his.append([trian_loss, test_loss])\n",
    "# writer.add_scalar(\"train_loss\", trian_loss, 0)\n",
    "# writer.add_scalar(\"test_loss\", test_loss, 0)\n",
    "# print('[{}] Epoch: {:03d}, Train loss: {:.2E}, Test loss: {:.2E} '.format(\n",
    "#     str(datetime.datetime.now().strftime('%H:%M:%S')), 0, trian_loss,test_loss))\n",
    "for epoch in range(0, 200):\n",
    "    train_loss = train(train_loader)\n",
    "    test_loss = test(test_loader)\n",
    "    his.append([train_loss, test_loss])\n",
    "    writer.add_scalar(\"train_loss\", train_loss, epoch)\n",
    "    writer.add_scalar(\"test_loss\", test_loss, epoch)\n",
    "    print('[{}] Epoch: {:03d}, Train loss: {:.2E}, Test loss: {:.2E} '.format(\n",
    "        str(datetime.datetime.now().strftime('%H:%M:%S')), epoch, train_loss,test_loss))\n",
    "    torch.save(his, 'his_final.txt')\n",
    "    torch.save(model.state_dict(), 'Models/RGNN_final.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "his = np.array(his)\n",
    "cmap1 = cm.get_cmap('Blues')(np.linspace(1, 0.5, 3))\n",
    "cmap2 = cm.get_cmap('Reds')(np.linspace(1, 0.5, 3))\n",
    "fig, ax = plt.subplots(1, figsize = (6,4))\n",
    "ax.plot(range(his.shape[0]), his[:,0], color=cmap1[0], label='training loss')\n",
    "ax.plot(range(his.shape[0]), his[:,1], color=cmap2[0], label='test loss')\n",
    "#ax.set_ylim([0,0.001])\n",
    "ax.set_ylabel('loss')\n",
    "ax.set_xlabel('epoch')\n",
    "ax.legend()\n",
    "# ax.set_ylim([-1,5])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'Models/RGNN_final.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Models/RGNN_final.pt'\n",
    "#model = Net()\n",
    "#model = DataParallel(model)\n",
    "#model = model.to(device)\n",
    "model.load_state_dict(torch.load(path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_temp_error(temp,data,time=99,zoom=3.0,show_edges=False,\n",
    "                        camera_position = [(200, 100, 100),(10.0, 10.0, 0.0), (0.0, 0.0, 1.0)],\n",
    "                        camera_position_zoom = [(200/3, 100/3, 100/3),(10.0, 10.0, 0.0), (0.0, 0.0, 1.0)]):\n",
    "    display = Display(visible=0)\n",
    "    _ = display.start()\n",
    "    output_show = temp[time-1,:,0]\n",
    "    range_ = [-max(-output_show.min(),output_show.max()), max(-output_show.min(),output_show.max())]\n",
    "    active_elements = [element.tolist() for element, birth_time in zip(data['elements'], data['birth_element'][:,time]) if birth_time > 0.5]\n",
    "    active_cells = np.array([item for sublist in active_elements for item in [8] + sublist])\n",
    "    active_cell_type = np.array([vtk.VTK_HEXAHEDRON] * len(active_elements))\n",
    "    points = np.array(data['pos'])\n",
    "    active_grid = pv.UnstructuredGrid(active_cells, active_cell_type, points)\n",
    "    active_grid.point_arrays['temp'] = np.array(output_show)\n",
    "    elements = [element.tolist() for element, birth_time in zip(data['elements'], data['birth_element']) if True]\n",
    "    cells = np.array([item for sublist in elements for item in [8] + sublist])\n",
    "    cell_type = np.array([vtk.VTK_HEXAHEDRON] * len(elements))\n",
    "    grid = pv.UnstructuredGrid(cells, cell_type, points)\n",
    "    grid.point_arrays['temp'] = np.array(output_show)\n",
    "    clipped = grid.clip('x', origin=(-2,0,0), invert=True)\n",
    "    p = pv.Plotter(shape=(1, 1), window_size=([800, 300]),)\n",
    "    p.camera_position = camera_position_zoom\n",
    "    p.add_mesh(active_grid, show_edges=show_edges, scalars='temp',cmap=\"coolwarm\",clim = range_)\n",
    "    p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_temp_history(temp,data,time=99,zoom=3.0,show_edges=False,\n",
    "                        camera_position = [(200, 100, 100),(10.0, 10.0, 0.0), (0.0, 0.0, 1.0)],\n",
    "                        camera_position_zoom = [(200/3, 100/3, 100/3),(10.0, 10.0, 0.0), (0.0, 0.0, 1.0)]):\n",
    "    display = Display(visible=0)\n",
    "    _ = display.start()\n",
    "    output_show = temp[time-1,:,0]\n",
    "    range_ = [300, 3000]\n",
    "    active_elements = [element.tolist() for element, birth_time in zip(data['elements'], data['birth_element'][:,time]) if birth_time > 0.5]\n",
    "    active_cells = np.array([item for sublist in active_elements for item in [8] + sublist])\n",
    "    active_cell_type = np.array([vtk.VTK_HEXAHEDRON] * len(active_elements))\n",
    "    points = np.array(data['pos'])\n",
    "    active_grid = pv.UnstructuredGrid(active_cells, active_cell_type, points)\n",
    "    active_grid.point_arrays['temp'] = np.array(output_show)\n",
    "    elements = [element.tolist() for element, birth_time in zip(data['elements'], data['birth_element']) if True]\n",
    "    cells = np.array([item for sublist in elements for item in [8] + sublist])\n",
    "    cell_type = np.array([vtk.VTK_HEXAHEDRON] * len(elements))\n",
    "    grid = pv.UnstructuredGrid(cells, cell_type, points)\n",
    "    grid.point_arrays['temp'] = np.array(output_show)\n",
    "    clipped = grid.clip('x', origin=(-2,0,0), invert=True)\n",
    "    p = pv.Plotter(shape=(1, 1), window_size=([800, 300]),)\n",
    "    p.camera_position = camera_position_zoom\n",
    "    p.add_mesh(active_grid, show_edges=show_edges, scalars='temp',cmap=\"coolwarm\",clim = range_)\n",
    "    p.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_id = np.random.randint(0,len(dataset))\n",
    "test_id = 0\n",
    "data = [test_dataset[test_id]]\n",
    "with torch.no_grad():\n",
    "    prediction =  model(data).to(\"cpu\")\n",
    "data = data[0].to(\"cpu\")\n",
    "output = data.y[:,1:,:].transpose(0,1)\n",
    "output = output*(5000-300) + 300\n",
    "prediction = prediction*(5000-300) + 300\n",
    "birth = data.x[:,1:,0].transpose(0,1).unsqueeze(2)\n",
    "prediction = prediction*birth\n",
    "output = output*birth\n",
    "error = np.array(prediction - output)\n",
    "error.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t = 29\n",
    "display_temp_history(output,data,time=t)\n",
    "display_temp_history(prediction,data,time=t)\n",
    "display_temp_error(prediction-output,data,time=t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.x[:,9,2].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_id = 2959\n",
    "prediction-output[:,point_id,0]\n",
    "cmap1 = cm.get_cmap('Blues')(np.linspace(1, 0.5, 3))\n",
    "cmap2 = cm.get_cmap('Reds')(np.linspace(1, 0.5, 3))\n",
    "cmap3 = cm.get_cmap('Greens')(np.linspace(1, 0.5, 3))\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize = (6,4))\n",
    "ax.plot(np.linspace(0.1, 3, 29),prediction[:,point_id,0], color=cmap1[0], label='predicted_temp')\n",
    "ax.plot(np.linspace(0.1, 3, 29),output[:,point_id,0], color=cmap2[0], label='actual_temp')\n",
    "ax.plot(np.linspace(0.1, 3, 29),output[:,point_id,0]-prediction[:,point_id,0], color=cmap3[0], label='error')\n",
    "ax.set_ylabel('temp (K)')\n",
    "ax.set_xlabel('time (s)')\n",
    "ax.legend()\n",
    "# ax.set_ylim([-1,5])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_id = '18'\n",
    "start_time = 5000\n",
    "seq_len = 3000\n",
    "\n",
    "# load simulation settings\n",
    "edge_index, elements, pos, birth_element, birth = load_simulation_input(simulation_id)\n",
    "toolpath, state, endTime = load_toolpath(simulation_id)\n",
    "\n",
    "# temperature output\n",
    "temperature = load_simulation_output(simulation_id)\n",
    "#temperature = torch.clamp(temperature, 300.0, 2000.0)\n",
    "\n",
    "# edge feature (length of each edge)\n",
    "edge_pos = pos[edge_index.long()]\n",
    "edge_dis = ((edge_pos[:, 0, :] - edge_pos[:, 1, :])**2).sum(dim = 1)\n",
    "\n",
    "# boundary feature (distance to fixed boundary condition at z = -20)\n",
    "boundary = pos[:, 2] + 20.0\n",
    "\n",
    "assert (temperature.shape[1] == pos.shape[0])\n",
    "\n",
    "x_data = torch.Tensor([])\n",
    "y_data = torch.Tensor([])\n",
    "birth_data = torch.Tensor([])\n",
    "for time_step in range(start_time, start_time + seq_len):\n",
    "    toolpath_current_step = toolpath[time_step]\n",
    "    state_current_step = state[time_step]   \n",
    "    r2 = (pos[:, 0] - toolpath_current_step[0])**2 + (pos[:, 1] - toolpath_current_step[1])**2 + (pos[:, 2] - toolpath_current_step[2])**2 + 0.1\n",
    "    if state_current_step == 1:\n",
    "        laser_feature = 1/r2\n",
    "    else:\n",
    "        laser_feature = r2 * 0.0                   \n",
    "\n",
    "    temp_time_step = temperature[time_step, :]\n",
    "    # temp_time_step_next = temperature[time_step + 1, :]\n",
    "\n",
    "    birth_time_step = (birth < time_step * 0.1).float()\n",
    "    # birth_time_step_next = (birth < (time_step + 1) * 0.1).float()\n",
    "\n",
    "    birth_time_element = (birth_element < time_step * 0.1).float()\n",
    "\n",
    "    x = torch.cat([\n",
    "    #              temp_time_step.unsqueeze(1),\n",
    "                   birth_time_step.unsqueeze(1),\n",
    "                   boundary.unsqueeze(1),\n",
    "                   laser_feature.unsqueeze(1)], dim = 1)\n",
    "    y = torch.cat([temp_time_step.unsqueeze(1),\n",
    "    #              temp_time_step_next.unsqueeze(1),\n",
    "    #              birth_time_step_next.unsqueeze(1)\n",
    "                  ], dim = 1)\n",
    "\n",
    "    x_data = torch.cat((x_data, x.unsqueeze(0)),0)\n",
    "    y_data = torch.cat((y_data, y.unsqueeze(0)),0)\n",
    "    birth_data = torch.cat((birth_data, birth_time_element.unsqueeze(0)),0)\n",
    "\n",
    "data_temp = Data(x=x_data, y=y_data, birth_element=birth_data,\n",
    "            pos = pos, edge_index=edge_index.t().contiguous(), edge_attr = edge_dis, elements=elements)\n",
    "\n",
    "data_x = data_temp['x']\n",
    "data_e = data_temp['edge_attr']\n",
    "data_y = data_temp['y']\n",
    "stats = torch.load(\"/home/mmv664/Documents/Graph_modeling/Graph_AM_Modeling/processed/stats\")\n",
    "\n",
    "# normalize boundary feature to the range of 0-1\n",
    "data_x[:,:,1] = (data_x[:,:,1] - stats[1,2]) / (stats[1,3] - stats[1,2])\n",
    "# normalize laser feature to mean of zeros and std of 1\n",
    "data_x[:,:,2] = (data_x[:,:,2] - stats[2,2]) / (stats[2,3] - stats[2,2])\n",
    "# nomalize edge feature to mean of zero and std of 1\n",
    "data_e = 1.0/data_e**0.5\n",
    "# normalize temperature to the range of 0-1\n",
    "data_y = (data_y.clamp(300,3000) - 300) / 2700\n",
    "\n",
    "data =  Data(\n",
    "            x=data_x.transpose(0,1), \n",
    "            y=data_y.transpose(0,1), \n",
    "            pos=data_temp['pos'], \n",
    "            edge_index=data_temp['edge_index'],\n",
    "            edge_attr = data_e.unsqueeze(1),\n",
    "            birth_element=data_temp['birth_element'].transpose(0,1),\n",
    "            elements=data_temp['elements']\n",
    "           )\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [data]\n",
    "with torch.no_grad():\n",
    "    prediction =  model(data).to(\"cpu\")\n",
    "data = data[0].to(\"cpu\")\n",
    "output = data.y[:,1:,:].transpose(0,1)\n",
    "output = output*(3000-300) + 300\n",
    "prediction = prediction*(3000-300) + 300\n",
    "birth = data.x[:,1:,0].transpose(0,1).unsqueeze(2)\n",
    "prediction = prediction*birth\n",
    "output = output*birth\n",
    "error = np.array(prediction - output)\n",
    "error.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 499\n",
    "display_temp_history(output,data,time=t)\n",
    "display_temp_history(prediction,data,time=t)\n",
    "display_temp_error(prediction-output,data,time=t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.x[:,399,2].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "point_id = 11403\n",
    "cmap1 = cm.get_cmap('Blues')(np.linspace(1, 0.5, 3))\n",
    "cmap2 = cm.get_cmap('Reds')(np.linspace(1, 0.5, 3))\n",
    "fig, ax = plt.subplots(1, figsize = (6,4))\n",
    "ax.plot(np.linspace(0.1, 300, 2999),prediction[:,point_id,0], color=cmap1[0], label='predicted_temp')\n",
    "ax.plot(np.linspace(0.1, 300, 2999),output[:,point_id,0], color=cmap2[0], label='actual_temp')\n",
    "error = output[:,point_id,0]-prediction[:,point_id,0]\n",
    "ax.plot(np.linspace(0.1, 300, 2999),error, color=cmap3[0], label='error',linestyle='dashed')\n",
    "errors.append(error.numpy())\n",
    "ax.set_ylabel('temp (K)')\n",
    "ax.set_xlabel('time (s)')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_id = 11844\n",
    "cmap1 = cm.get_cmap('Blues')(np.linspace(1, 0.5, 3))\n",
    "cmap2 = cm.get_cmap('Reds')(np.linspace(1, 0.5, 3))\n",
    "fig, ax = plt.subplots(1, figsize = (6,4))\n",
    "ax.plot(np.linspace(0.1, 300, 2999),prediction[:,point_id,0], color=cmap1[0], label='predicted_temp')\n",
    "ax.plot(np.linspace(0.1, 300, 2999),output[:,point_id,0], color=cmap2[0], label='actual_temp')\n",
    "error = output[:,point_id,0]-prediction[:,point_id,0]\n",
    "ax.plot(np.linspace(0.1, 300, 2999),error, color=cmap3[0], label='error',linestyle='dashed')\n",
    "errors.append(error.numpy())\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_id = 446\n",
    "cmap1 = cm.get_cmap('Blues')(np.linspace(1, 0.5, 3))\n",
    "cmap2 = cm.get_cmap('Reds')(np.linspace(1, 0.5, 3))\n",
    "fig, ax = plt.subplots(1, figsize = (6,4))\n",
    "ax.plot(np.linspace(0.1, 300, 2999),prediction[:,point_id,0], color=cmap1[0], label='predicted_temp')\n",
    "ax.plot(np.linspace(0.1, 300, 2999),output[:,point_id,0], color=cmap2[0], label='actual_temp')\n",
    "error = output[:,point_id,0]-prediction[:,point_id,0]\n",
    "ax.plot(np.linspace(0.1, 300, 2999),error, color=cmap3[0], label='error',linestyle='dashed')\n",
    "errors.append(error.numpy())\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(errors,'err.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
